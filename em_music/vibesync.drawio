<mxfile host="app.diagrams.net" agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36" version="26.0.16">
  <diagram name="Page-1" id="LyAcxEIUK0LsX1fmSSqz">
    <mxGraphModel dx="794" dy="446" grid="1" gridSize="10" guides="1" tooltips="1" connect="1" arrows="1" fold="1" page="1" pageScale="1" pageWidth="827" pageHeight="1169" math="0" shadow="0">
      <root>
        <mxCell id="0" />
        <mxCell id="1" parent="0" />
        <UserObject label="" plantUmlData="{&#xa;  &quot;data&quot;: &quot;import streamlit as st\nfrom streamlit_webrtc import webrtc_streamer\nimport av\nimport cv2\nimport numpy as np\nimport mediapipe as mp\nfrom keras.models import load_model\nimport webbrowser\nimport os\nimport pandas as pd\n\n# Sample user credentials\nUSER_CREDENTIALS = {\&quot;user1\&quot;: \&quot;password1\&quot;, \&quot;user2\&quot;: \&quot;password2\&quot;}\n\n# Paths for model and labels\nmodel_path = os.path.join(os.path.abspath(os.path.join(os.getcwd(), os.pardir)), \&quot;model.h5\&quot;)\nlabels_path = os.path.join(os.path.abspath(os.path.join(os.getcwd(), os.pardir)), \&quot;labels.npy\&quot;)\n\n# Load model and labels\nmodel = load_model(model_path)\nlabel = np.load(labels_path)\n\n# Mediapipe setup\nholistic = mp.solutions.holistic\nhands = mp.solutions.hands\nholis = holistic.Holistic()\ndrawing = mp.solutions.drawing_utils\n\n# Inject CSS for styling\nst.markdown(\n    \&quot;\&quot;\&quot;\n    &lt;style&gt;\n    .main {\n        background-color: #f7f7f7;\n    }\n    h1 {\n        color: #1f77b4;\n        text-align: center;\n        font-family: &#39;Arial&#39;, sans-serif;\n    }\n    .stButton &gt; button {\n        background-color: #4CAF50;\n        color: white;\n        border: none;\n        border-radius: 5px;\n        padding: 10px 20px;\n        font-size: 16px;\n    }\n    .stButton &gt; button:hover {\n        background-color: #45a049;\n        cursor: pointer;\n    }\n    .stTextInput &gt; div &gt; input {\n        border: 2px solid #1f77b4;\n        border-radius: 5px;\n        padding: 5px;\n        font-size: 14px;\n    }\n    .stTextInput &gt; div &gt; input:focus {\n        outline: none;\n        border-color: #45a049;\n    }\n    &lt;/style&gt;\n    \&quot;\&quot;\&quot;,\n    unsafe_allow_html=True,\n)\n\n# Function to display login page\ndef login():\n    st.title(\&quot;Login\&quot;)\n    username = st.text_input(\&quot;Username\&quot;, placeholder=\&quot;Enter your username\&quot;)\n    password = st.text_input(\&quot;Password\&quot;, type=\&quot;password\&quot;, placeholder=\&quot;Enter your password\&quot;)\n    login_button = st.button(\&quot;Login\&quot;)\n\n    if login_button:\n        if username in USER_CREDENTIALS and USER_CREDENTIALS[username] == password:\n            st.session_state[\&quot;authenticated\&quot;] = True\n            st.success(\&quot;Login successful!\&quot;)\n        else:\n            st.error(\&quot;Invalid username or password\&quot;)\n\n# Function to display the main application\ndef main_app():\n    st.header(\&quot;í ¼í¾µ Emotion-Based Music Recommender í ¼í¾µ\&quot;)\n    \n    if \&quot;run\&quot; not in st.session_state:\n        st.session_state[\&quot;run\&quot;] = \&quot;true\&quot;\n\n    try:\n        emotion = np.load(\&quot;emotion.npy\&quot;)[0]\n    except:\n        emotion = \&quot;\&quot;\n\n    if not emotion:\n        st.session_state[\&quot;run\&quot;] = \&quot;true\&quot;\n    else:\n        st.session_state[\&quot;run\&quot;] = \&quot;false\&quot;\n\n    class EmotionProcessor:\n        def recv(self, frame):\n            frm = frame.to_ndarray(format=\&quot;bgr24\&quot;)\n\n            frm = cv2.flip(frm, 1)\n            res = holis.process(cv2.cvtColor(frm, cv2.COLOR_BGR2RGB))\n            lst = []\n\n            if res.face_landmarks:\n                for i in res.face_landmarks.landmark:\n                    lst.append(i.x - res.face_landmarks.landmark[1].x)\n                    lst.append(i.y - res.face_landmarks.landmark[1].y)\n\n                if res.left_hand_landmarks:\n                    for i in res.left_hand_landmarks.landmark:\n                        lst.append(i.x - res.left_hand_landmarks.landmark[8].x)\n                        lst.append(i.y - res.left_hand_landmarks.landmark[8].y)\n                else:\n                    lst.extend([0.0] * 42)\n\n                if res.right_hand_landmarks:\n                    for i in res.right_hand_landmarks.landmark:\n                        lst.append(i.x - res.right_hand_landmarks.landmark[8].x)\n                        lst.append(i.y - res.right_hand_landmarks.landmark[8].y)\n                else:\n                    lst.extend([0.0] * 42)\n\n                lst = np.array(lst).reshape(1, -1)\n                pred = label[np.argmax(model.predict(lst))]\n\n                print(pred)\n                cv2.putText(frm, pred, (50, 50), cv2.FONT_ITALIC, 1, (255, 0, 0), 2)\n                np.save(\&quot;emotion.npy\&quot;, np.array([pred]))\n\n            drawing.draw_landmarks(frm, res.face_landmarks, holistic.FACEMESH_TESSELATION,\n                                   landmark_drawing_spec=drawing.DrawingSpec(color=(0, 0, 255), thickness=-1, circle_radius=1),\n                                   connection_drawing_spec=drawing.DrawingSpec(thickness=1))\n            drawing.draw_landmarks(frm, res.left_hand_landmarks, hands.HAND_CONNECTIONS)\n            drawing.draw_landmarks(frm, res.right_hand_landmarks, hands.HAND_CONNECTIONS)\n\n            return av.VideoFrame.from_ndarray(frm, format=\&quot;bgr24\&quot;)\n\n    lang = st.text_input(\&quot;Language\&quot;, placeholder=\&quot;e.g., English, Hindi, etc.\&quot;)\n    singer = st.text_input(\&quot;Singer\&quot;, placeholder=\&quot;e.g., Arijit Singh, Taylor Swift, etc.\&quot;)\n\n    if lang and singer and st.session_state[\&quot;run\&quot;] != \&quot;false\&quot;:\n        webrtc_streamer(key=\&quot;key\&quot;, desired_playing_state=True, video_processor_factory=EmotionProcessor)\n\n    btn = st.button(\&quot;Recommend me songs\&quot;)\n\n    if btn:\n        if not emotion:\n            st.warning(\&quot;Please let me capture your emotion first.\&quot;)\n            st.session_state[\&quot;run\&quot;] = \&quot;true\&quot;\n        else:\n            query = f\&quot;{lang} {emotion} song {singer}\&quot;\n            st.info(f\&quot;Searching for: {query}\&quot;)\n            webbrowser.open(f\&quot;https://www.youtube.com/results?search_query={query}\&quot;)\n            np.save(\&quot;emotion.npy\&quot;, np.array([\&quot;\&quot;]))\n            st.session_state[\&quot;run\&quot;] = \&quot;true\&quot;\n\n# Function to display feedback page\ndef feedback_page():\n    st.header(\&quot;í ½í²¬ Feedback\&quot;)\n    name = st.text_input(\&quot;Your Name\&quot;, placeholder=\&quot;Enter your name\&quot;)\n    email = st.text_input(\&quot;Your Email\&quot;, placeholder=\&quot;Enter your email\&quot;)\n    feedback = st.text_area(\&quot;Your Feedback\&quot;, placeholder=\&quot;Write your feedback here...\&quot;)\n    submit_btn = st.button(\&quot;Submit Feedback\&quot;)\n\n    if submit_btn:\n        if name and email and feedback:\n            # Save feedback to a CSV file\n            feedback_data = {\&quot;Name\&quot;: [name], \&quot;Email\&quot;: [email], \&quot;Feedback\&quot;: [feedback]}\n            feedback_df = pd.DataFrame(feedback_data)\n            feedback_file = \&quot;feedback.csv\&quot;\n\n            if os.path.exists(feedback_file):\n                feedback_df.to_csv(feedback_file, mode=&#39;a&#39;, header=False, index=False)\n            else:\n                feedback_df.to_csv(feedback_file, index=False)\n\n            st.success(\&quot;Thank you for your feedback!\&quot;)\n        else:\n            st.error(\&quot;Please fill out all fields.\&quot;)\n\n# Main flow\nif \&quot;authenticated\&quot; not in st.session_state:\n    st.session_state[\&quot;authenticated\&quot;] = False\n\nmenu = [\&quot;Login\&quot;, \&quot;Main App\&quot;, \&quot;Feedback\&quot;]\nchoice = st.sidebar.selectbox(\&quot;Menu\&quot;, menu)\n\nif choice == \&quot;Login\&quot; and not st.session_state[\&quot;authenticated\&quot;]:\n    login()\nelif choice == \&quot;Main App\&quot; and st.session_state[\&quot;authenticated\&quot;]:\n    main_app()\nelif choice == \&quot;Feedback\&quot; and st.session_state[\&quot;authenticated\&quot;]:\n    feedback_page()\nelse:\n    st.warning(\&quot;Please log in to access this feature.\&quot;)\n\n##################y\n# cd############################################\n# import streamlit as st\n# from streamlit_webrtc import webrtc_streamer\n# import av\n# import cv2\n# import numpy as np\n# import mediapipe as mp\n# from keras.models import load_model\n# import webbrowser\n# import os\n\n# # Sample user credentials\n# USER_CREDENTIALS = {\&quot;user1\&quot;: \&quot;password1\&quot;, \&quot;user2\&quot;: \&quot;password2\&quot;}\n\n# # Paths for model and labels\n# model_path = os.path.join(os.path.abspath(os.path.join(os.getcwd(), os.pardir)), \&quot;model.h5\&quot;)\n# labels_path = os.path.join(os.path.abspath(os.path.join(os.getcwd(), os.pardir)), \&quot;labels.npy\&quot;)\n\n# # Load model and labels\n# model = load_model(model_path)\n# label = np.load(labels_path)\n\n# # Mediapipe setup\n# holistic = mp.solutions.holistic\n# hands = mp.solutions.hands\n# holis = holistic.Holistic()\n# drawing = mp.solutions.drawing_utils\n\n# # Inject CSS for styling\n# st.markdown(\n#     \&quot;\&quot;\&quot;\n#     &lt;style&gt;\n#     .main {\n#         background-color: #f7f7f7;\n#     }\n#     h1 {\n#         color: #1f77b4;\n#         text-align: center;\n#         font-family: &#39;Arial&#39;, sans-serif;\n#     }\n#     .stButton &gt; button {\n#         background-color: #4CAF50;\n#         color: white;\n#         border: none;\n#         border-radius: 5px;\n#         padding: 10px 20px;\n#         font-size: 16px;\n#     }\n#     .stButton &gt; button:hover {\n#         background-color: #45a049;\n#         cursor: pointer;\n#     }\n#     .stTextInput &gt; div &gt; input {\n#         border: 2px solid #1f77b4;\n#         border-radius: 5px;\n#         padding: 5px;\n#         font-size: 14px;\n#     }\n#     .stTextInput &gt; div &gt; input:focus {\n#         outline: none;\n#         border-color: #45a049;\n#     }\n#     &lt;/style&gt;\n#     \&quot;\&quot;\&quot;,\n#     unsafe_allow_html=True,\n# )\n\n# # Function to display login page\n# def login():\n#     st.title(\&quot;Login\&quot;)\n#     username = st.text_input(\&quot;Username\&quot;, placeholder=\&quot;Enter your username\&quot;)\n#     password = st.text_input(\&quot;Password\&quot;, type=\&quot;password\&quot;, placeholder=\&quot;Enter your password\&quot;)\n#     login_button = st.button(\&quot;Login\&quot;)\n\n#     if login_button:\n#         if username in USER_CREDENTIALS and USER_CREDENTIALS[username] == password:\n#             st.session_state[\&quot;authenticated\&quot;] = True\n#             st.success(\&quot;Login successful!\&quot;)\n#         else:\n#             st.error(\&quot;Invalid username or password\&quot;)\n\n# # Function to display the main application\n# def main_app():\n#     st.header(\&quot;í ¼í¾µ Emotion-Based Music Recommender í ¼í¾µ\&quot;)\n    \n#     if \&quot;run\&quot; not in st.session_state:\n#         st.session_state[\&quot;run\&quot;] = \&quot;true\&quot;\n\n#     try:\n#         emotion = np.load(\&quot;emotion.npy\&quot;)[0]\n#     except:\n#         emotion = \&quot;\&quot;\n\n#     if not emotion:\n#         st.session_state[\&quot;run\&quot;] = \&quot;true\&quot;\n#     else:\n#         st.session_state[\&quot;run\&quot;] = \&quot;false\&quot;\n\n#     class EmotionProcessor:\n#         def recv(self, frame):\n#             frm = frame.to_ndarray(format=\&quot;bgr24\&quot;)\n\n#             frm = cv2.flip(frm, 1)\n#             res = holis.process(cv2.cvtColor(frm, cv2.COLOR_BGR2RGB))\n#             lst = []\n\n#             if res.face_landmarks:\n#                 for i in res.face_landmarks.landmark:\n#                     lst.append(i.x - res.face_landmarks.landmark[1].x)\n#                     lst.append(i.y - res.face_landmarks.landmark[1].y)\n\n#                 if res.left_hand_landmarks:\n#                     for i in res.left_hand_landmarks.landmark:\n#                         lst.append(i.x - res.left_hand_landmarks.landmark[8].x)\n#                         lst.append(i.y - res.left_hand_landmarks.landmark[8].y)\n#                 else:\n#                     lst.extend([0.0] * 42)\n\n#                 if res.right_hand_landmarks:\n#                     for i in res.right_hand_landmarks.landmark:\n#                         lst.append(i.x - res.right_hand_landmarks.landmark[8].x)\n#                         lst.append(i.y - res.right_hand_landmarks.landmark[8].y)\n#                 else:\n#                     lst.extend([0.0] * 42)\n\n#                 lst = np.array(lst).reshape(1, -1)\n#                 pred = label[np.argmax(model.predict(lst))]\n\n#                 print(pred)\n#                 cv2.putText(frm, pred, (50, 50), cv2.FONT_ITALIC, 1, (255, 0, 0), 2)\n#                 np.save(\&quot;emotion.npy\&quot;, np.array([pred]))\n\n#             drawing.draw_landmarks(frm, res.face_landmarks, holistic.FACEMESH_TESSELATION,\n#                                    landmark_drawing_spec=drawing.DrawingSpec(color=(0, 0, 255), thickness=-1, circle_radius=1),\n#                                    connection_drawing_spec=drawing.DrawingSpec(thickness=1))\n#             drawing.draw_landmarks(frm, res.left_hand_landmarks, hands.HAND_CONNECTIONS)\n#             drawing.draw_landmarks(frm, res.right_hand_landmarks, hands.HAND_CONNECTIONS)\n\n#             return av.VideoFrame.from_ndarray(frm, format=\&quot;bgr24\&quot;)\n\n#     lang = st.text_input(\&quot;Language\&quot;, placeholder=\&quot;e.g., English, Hindi, etc.\&quot;)\n#     singer = st.text_input(\&quot;Singer\&quot;, placeholder=\&quot;e.g., Arijit Singh, Taylor Swift, etc.\&quot;)\n\n#     if lang and singer and st.session_state[\&quot;run\&quot;] != \&quot;false\&quot;:\n#         webrtc_streamer(key=\&quot;key\&quot;, desired_playing_state=True, video_processor_factory=EmotionProcessor)\n\n#     btn = st.button(\&quot;Recommend me songs\&quot;)\n\n#     if btn:\n#         if not emotion:\n#             st.warning(\&quot;Please let me capture your emotion first.\&quot;)\n#             st.session_state[\&quot;run\&quot;] = \&quot;true\&quot;\n#         else:\n#             query = f\&quot;{lang} {emotion} song {singer}\&quot;\n#             st.info(f\&quot;Searching for: {query}\&quot;)\n#             webbrowser.open(f\&quot;https://www.youtube.com/results?search_query={query}\&quot;)\n#             np.save(\&quot;emotion.npy\&quot;, np.array([\&quot;\&quot;]))\n#             st.session_state[\&quot;run\&quot;] = \&quot;true\&quot;\n\n# # Main flow\n# if \&quot;authenticated\&quot; not in st.session_state:\n#     st.session_state[\&quot;authenticated\&quot;] = False\n\n# if not st.session_state[\&quot;authenticated\&quot;]:\n#     login()\n# else:\n#     main_app()\n\n#################################################################\n################################################################\n# import streamlit as st\n# from streamlit_webrtc import webrtc_streamer\n# import av\n# import cv2\n# import numpy as np\n# import mediapipe as mp\n# from keras.models import load_model\n# import webbrowser\n# import os\n\n# # Sample user credentials\n# USER_CREDENTIALS = {\&quot;user1\&quot;: \&quot;password1\&quot;, \&quot;user2\&quot;: \&quot;password2\&quot;}\n\n# # Paths for model and labels\n# model_path = os.path.join(os.path.abspath(os.path.join(os.getcwd(), os.pardir)), \&quot;model.h5\&quot;)\n# labels_path = os.path.join(os.path.abspath(os.path.join(os.getcwd(), os.pardir)), \&quot;labels.npy\&quot;)\n\n# # Load model and labels\n# model = load_model(model_path)\n# label = np.load(labels_path)\n\n# # Mediapipe setup\n# holistic = mp.solutions.holistic\n# hands = mp.solutions.hands\n# holis = holistic.Holistic()\n# drawing = mp.solutions.drawing_utils\n\n# # Function to display login page\n# def login():\n#     st.title(\&quot;Login\&quot;)\n#     username = st.text_input(\&quot;Username\&quot;)\n#     password = st.text_input(\&quot;Password\&quot;, type=\&quot;password\&quot;)\n#     login_button = st.button(\&quot;Login\&quot;)\n\n#     if login_button:\n#         if username in USER_CREDENTIALS and USER_CREDENTIALS[username] == password:\n#             st.session_state[\&quot;authenticated\&quot;] = True\n#             st.success(\&quot;Login successful!\&quot;)\n#         else:\n#             st.error(\&quot;Invalid username or password\&quot;)\n\n# # Function to display the main application\n# def main_app():\n#     st.header(\&quot;Emotion Based Music Recommender\&quot;)\n    \n#     if \&quot;run\&quot; not in st.session_state:\n#         st.session_state[\&quot;run\&quot;] = \&quot;true\&quot;\n\n#     try:\n#         emotion = np.load(\&quot;emotion.npy\&quot;)[0]\n#     except:\n#         emotion = \&quot;\&quot;\n\n#     if not emotion:\n#         st.session_state[\&quot;run\&quot;] = \&quot;true\&quot;\n#     else:\n#         st.session_state[\&quot;run\&quot;] = \&quot;false\&quot;\n\n#     class EmotionProcessor:\n#         def recv(self, frame):\n#             frm = frame.to_ndarray(format=\&quot;bgr24\&quot;)\n\n#             frm = cv2.flip(frm, 1)\n#             res = holis.process(cv2.cvtColor(frm, cv2.COLOR_BGR2RGB))\n#             lst = []\n\n#             if res.face_landmarks:\n#                 for i in res.face_landmarks.landmark:\n#                     lst.append(i.x - res.face_landmarks.landmark[1].x)\n#                     lst.append(i.y - res.face_landmarks.landmark[1].y)\n\n#                 if res.left_hand_landmarks:\n#                     for i in res.left_hand_landmarks.landmark:\n#                         lst.append(i.x - res.left_hand_landmarks.landmark[8].x)\n#                         lst.append(i.y - res.left_hand_landmarks.landmark[8].y)\n#                 else:\n#                     lst.extend([0.0] * 42)\n\n#                 if res.right_hand_landmarks:\n#                     for i in res.right_hand_landmarks.landmark:\n#                         lst.append(i.x - res.right_hand_landmarks.landmark[8].x)\n#                         lst.append(i.y - res.right_hand_landmarks.landmark[8].y)\n#                 else:\n#                     lst.extend([0.0] * 42)\n\n#                 lst = np.array(lst).reshape(1, -1)\n#                 pred = label[np.argmax(model.predict(lst))]\n\n#                 print(pred)\n#                 cv2.putText(frm, pred, (50, 50), cv2.FONT_ITALIC, 1, (255, 0, 0), 2)\n#                 np.save(\&quot;emotion.npy\&quot;, np.array([pred]))\n\n#             drawing.draw_landmarks(frm, res.face_landmarks, holistic.FACEMESH_TESSELATION,\n#                                    landmark_drawing_spec=drawing.DrawingSpec(color=(0, 0, 255), thickness=-1, circle_radius=1),\n#                                    connection_drawing_spec=drawing.DrawingSpec(thickness=1))\n#             drawing.draw_landmarks(frm, res.left_hand_landmarks, hands.HAND_CONNECTIONS)\n#             drawing.draw_landmarks(frm, res.right_hand_landmarks, hands.HAND_CONNECTIONS)\n\n#             return av.VideoFrame.from_ndarray(frm, format=\&quot;bgr24\&quot;)\n\n#     lang = st.text_input(\&quot;Language\&quot;)\n#     singer = st.text_input(\&quot;Singer\&quot;)\n\n#     if lang and singer and st.session_state[\&quot;run\&quot;] != \&quot;false\&quot;:\n#         webrtc_streamer(key=\&quot;key\&quot;, desired_playing_state=True, video_processor_factory=EmotionProcessor)\n\n#     btn = st.button(\&quot;Recommend me songs\&quot;)\n\n#     if btn:\n#         if not emotion:\n#             st.warning(\&quot;Please let me capture your emotion first.\&quot;)\n#             st.session_state[\&quot;run\&quot;] = \&quot;true\&quot;\n#         else:\n#             query = f\&quot;{lang} {emotion} song {singer}\&quot;\n#             st.info(f\&quot;Searching for: {query}\&quot;)\n#             webbrowser.open(f\&quot;https://www.youtube.com/results?search_query={query}\&quot;)\n#             np.save(\&quot;emotion.npy\&quot;, np.array([\&quot;\&quot;]))\n#             st.session_state[\&quot;run\&quot;] = \&quot;true\&quot;\n\n# # Main flow\n# if \&quot;authenticated\&quot; not in st.session_state:\n#     st.session_state[\&quot;authenticated\&quot;] = False\n\n# if not st.session_state[\&quot;authenticated\&quot;]:\n#     login()\n# else:\n#     main_app()\n####################################################################\n####################################################################\n# import streamlit as st\n# from streamlit_webrtc import webrtc_streamer\n# import av\n# import cv2 \n# import numpy as np \n# import mediapipe as mp \n# from keras.models import load_model\n# import webbrowser\n# import os\n\n# # Paths for model and labels\n# model_path = os.path.join(os.path.abspath(os.path.join(os.getcwd(), os.pardir)), \&quot;model.h5\&quot;)\n# labels_path = os.path.join(os.path.abspath(os.path.join(os.getcwd(), os.pardir)), \&quot;labels.npy\&quot;)\n\n# # Folder path for saving emotion.npy\n\n# # Load model and labels\n# model  = load_model(model_path)\n# label = np.load(labels_path)\n\n# # Mediapipe setup\n# holistic = mp.solutions.holistic\n# hands = mp.solutions.hands\n# holis = holistic.Holistic()\n# drawing = mp.solutions.drawing_utils\n\n# # Streamlit setup\n# st.header(\&quot;Emotion Based Music Recommender\&quot;)\n# if \&quot;run\&quot; not in st.session_state:\n#     st.session_state[\&quot;run\&quot;] = \&quot;true\&quot;\n\n# try:\n#     emotion = np.load(\&quot;emotion.npy\&quot;)[0]\n# except:\n#     emotion = \&quot;\&quot;\n\n# if not(emotion):\n#     st.session_state[\&quot;run\&quot;] = \&quot;true\&quot;\n# else:\n#     st.session_state[\&quot;run\&quot;] = \&quot;false\&quot;\n    \n\n# class EmotionProcessor:\n#     def recv(self, frame):\n#         frm = frame.to_ndarray(format=\&quot;bgr24\&quot;)\n\n#         ##############################\n#         frm = cv2.flip(frm, 1)\n\n#         res = holis.process(cv2.cvtColor(frm, cv2.COLOR_BGR2RGB))\n\n#         lst = []\n\n#         if res.face_landmarks:\n#             for i in res.face_landmarks.landmark:\n#                 lst.append(i.x - res.face_landmarks.landmark[1].x)\n#                 lst.append(i.y - res.face_landmarks.landmark[1].y)\n\n#             if res.left_hand_landmarks:\n#                 for i in res.left_hand_landmarks.landmark:\n#                     lst.append(i.x - res.left_hand_landmarks.landmark[8].x)\n#                     lst.append(i.y - res.left_hand_landmarks.landmark[8].y)\n#             else:\n#                 for i in range(42):\n#                     lst.append(0.0)\n\n#             if res.right_hand_landmarks:\n#                 for i in res.right_hand_landmarks.landmark:\n#                     lst.append(i.x - res.right_hand_landmarks.landmark[8].x)\n#                     lst.append(i.y - res.right_hand_landmarks.landmark[8].y)\n#             else:\n#                 for i in range(42):\n#                     lst.append(0.0)\n\n#             lst = np.array(lst).reshape(1, -1)\n\n#             pred = label[np.argmax(model.predict(lst))]\n\n#             print(pred)\n#             cv2.putText(frm, pred, (50, 50), cv2.FONT_ITALIC, 1, (255, 0, 0), 2)\n\n#             # Save the emotion prediction to the defined file path\n#             np.save(\&quot;emotion.npy\&quot;, np.array([pred]))\n\n#         drawing.draw_landmarks(frm, res.face_landmarks, holistic.FACEMESH_TESSELATION,\n#                                landmark_drawing_spec=drawing.DrawingSpec(color=(0, 0, 255), thickness=-1, circle_radius=1),\n#                                connection_drawing_spec=drawing.DrawingSpec(thickness=1))\n#         drawing.draw_landmarks(frm, res.left_hand_landmarks, hands.HAND_CONNECTIONS)\n#         drawing.draw_landmarks(frm, res.right_hand_landmarks, hands.HAND_CONNECTIONS)\n\n#         ##############################\n\n#         return av.VideoFrame.from_ndarray(frm, format=\&quot;bgr24\&quot;)\n\n# # Inputs for language and singer\n# lang = st.text_input(\&quot;Language\&quot;)\n# singer = st.text_input(\&quot;singer\&quot;)\n\n# # Start the webrtc streamer if the inputs are provided\n# if lang and singer and st.session_state[\&quot;run\&quot;] != \&quot;false\&quot;:\n#     webrtc_streamer(key=\&quot;key\&quot;, desired_playing_state=True, video_processor_factory=EmotionProcessor)\n\n# # Button to recommend songs\n# btn = st.button(\&quot;Recommend me songs\&quot;)\n\n# if btn:\n#     if not emotion:\n#         st.warning(\&quot;Please let me capture your emotion first.\&quot;)\n#         st.session_state[\&quot;run\&quot;] = \&quot;true\&quot;\n#     else:\n#         # Construct and open the YouTube query\n#         query = f\&quot;{lang} {emotion} song {singer}\&quot;\n#         st.info(f\&quot;Searching for: {query}\&quot;)\n#         webbrowser.open(f\&quot;https://www.youtube.com/results?search_query={query}\&quot;)\n        \n#         # Reset emotion and session state\n        # np.save(\&quot;emotion.npy\&quot;, np.array([\&quot;\&quot;]))  # Clear saved emotion\n        # st.session_state[\&quot;run\&quot;] = \&quot;true\&quot;  # Enable fresh capture\n\n\n&quot;,&#xa;  &quot;format&quot;: &quot;svg&quot;&#xa;}" id="c-mZ5FdJbWtEzwMXOex2-2">
          <mxCell style="shape=image;noLabel=1;verticalAlign=top;aspect=fixed;imageAspect=0;image=data:image/svg+xml,<?xml version="1.0" encoding="us-ascii" standalone="no"?><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" contentStyleType="text/css" height="151px" preserveAspectRatio="none" style="width:394px;height:151px;background:#000000;" version="1.1" viewBox="0 0 394 151" width="394px" zoomAndPan="magnify"><defs/><g><rect fill="#0D0D11" height="1" style="stroke:#0D0D11;stroke-width:1.0;" width="1" x="0" y="0"/><text fill="#33FF02" font-family="sans-serif" font-size="12" font-style="italic" font-weight="bold" lengthAdjust="spacing" textLength="107" x="5" y="17">PlantUML 1.2024.4</text><text fill="#33FF02" font-family="sans-serif" font-size="12" font-style="italic" font-weight="bold" lengthAdjust="spacing" textLength="6" x="5" y="29.8438">&#160;</text><text fill="#33FF02" font-family="sans-serif" font-size="12" font-style="italic" font-weight="bold" lengthAdjust="spacing" textLength="380" x="5" y="42.6875">&lt;b&gt;This version of PlantUML is 324 days old, so you should</text><text fill="#33FF02" font-family="sans-serif" font-size="12" font-style="italic" font-weight="bold" lengthAdjust="spacing" textLength="370" x="5" y="55.5313">&lt;b&gt;consider upgrading from https://plantuml.com/download</text><rect fill="#33FF02" height="19.9844" style="stroke:#33FF02;stroke-width:1.0;" width="166" x="5" y="64.375"/><text fill="#000000" font-family="sans-serif" font-size="14" font-weight="bold" lengthAdjust="spacing" textLength="164" x="6" y="79.375">[From string (line 2) ]</text><text fill="#33FF02" font-family="sans-serif" font-size="14" font-weight="bold" lengthAdjust="spacing" textLength="7" x="5" y="98.3594">&#160;</text><text fill="#33FF02" font-family="sans-serif" font-size="14" font-weight="bold" lengthAdjust="spacing" textLength="64" x="5" y="113.3438">@startuml</text><text fill="#33FF02" font-family="sans-serif" font-size="14" font-weight="bold" lengthAdjust="spacing" text-decoration="wavy underline" textLength="156" x="5" y="128.3281">import streamlit as st</text><text fill="#FF0000" font-family="sans-serif" font-size="14" font-weight="bold" lengthAdjust="spacing" textLength="91" x="12" y="143.3125">Syntax Error?</text><!--SRC=[xLlRRjl86RxNKyoI5w4AcR4DkscLrHQE8syCE4vWURTO60On8eSIDnJ99OUILSElq8k-G5-WjtslFaB_cU7v89Aox1OBQHSMEOV_DAT_lY-o5fxhKnHGd-25RL640tZfcRwxI0kr5PdwL4UMQ2pUD55D_5vKZ9VnaxuyZX-TSE6jcL37YuiMnB2mPtc45IyyeUiRyN6WBbo3s46intQneV6YNgfvwhkh85Ng1l6JXnq31CB_dj7hoMY25vvDK0YDaUuJWpZKmdRG-saolj7ERyOVnzUtbsTN4pH2Zn9hTIGDaUJX85Yvld4a3H0lFSwM7ajFJFHNJES1CbqVSUiGQ4OsdeBfFLwWUT00vBg1ofxKNrtBKU8NF0tOjrAid16ghmobFn3TVCFo-_0YSOdg_5JgzuIEdKeN8bN7MuDySEqAObxZ5QXCHqH97OtiWch7KraB9MCd5_ev6V60qD3hpLtR2gYbGvU5fmQk7LBBTG8rBk_DGNTGgcM5eYzKnMtLJz63qkyPFbvPpgpOCIhMu1Ly0NikdL-9Jj7vPC87CQ1h6-fx0LKNsFzck2j7wI7uI9B4lxzdBSWF_1cQM0vwvC_iCyNwjvdlXevneBkswm-HRBvZ_xtdJPxut_bHfaVSxCXyzsvwyZuff-I17c3RcZb3fCDi9NvQPxeEFJ3nmhBNG_Jcp8UP_6Q00km41p17BJEhJ0teXv1Irq4_eAbus6ZkoVdPnUdX-w9zgxb5ILewXUbFeDXndLBfWOyDAmo6wDHxIEiyR1WGrY4wElGUqF5Xjexx4rX_8r3xnxYYplpXt5t28jxin2a-FFbpnedG3rY51_C_YMIYu1P2VUbu8GKTXhM4lnP_UoovUmocmqooZF9ujVBzjCxhavBNDKODJLSFWunfRaXXkfAQeQWAY53n_TlCD8QfFU0FeHDWasZOjjsLDgSBUtJhXsJGumlt8dHqjeOGTS6amBFn6lQ06Im03yz8po2cU5NwGouCLX2rg4qKwOeLmvR2LS0KTU2aW7N96e2R6lTCaNwAQc2p1TawWKKDFeoaCHipj7P3F-aSoOftuhAihr4DoA9hZuoIJNk3yAI94CvzqQ8rmnM8vzGTtimoSos7oH10HU8hnAXqqh0TjLXu5_UuHwDHOb0gCmfhG8801W8ENKp9dOH3EcS7cWvlXWHT4HkrKgTGrw5VP3wANitG_Yvoc7rWfoObTSJtNL-HBfqbPdC_yShDnQncXe1fYE-IsFDiPYBKyxd22ZKep4oNES4mA8hqdt_-_Tzel71PsuCFE206-Xm6S4JS4DrTB8W3hH1h55aU3uJaXuu4Au6oW1VZbBfLZY3hn-8cKGYS90QM-kkq2n76P8urAIeIf-NTuJrlInvquj6gVfAKp1TcO5JHmQZoy6peOa9o4pkYsp18SJY_-YuRTjWL4Z5iC7oYBvM0sEO0cJwCRJy_2Kn_0L9vZKfT3N8htyTh1SxB1QOZQJhpZq_Y1P7l0zcVQjgMfy3h01trSqryaXpUgYSCKrW7VKdFsSubEh6IyozNNswq3p_U7D_y-A6Vbs875AJStUVLMyofG3LXhMish3Lsc0TvhyGkx2EBJPToOpL-AlUArAemVM4oAfRwW0usIRWxkbSV-irYrirYreKmPtorYKarbXXjShZaT4Ml1izhlTyawkvFjI6e3KEJl7LPNda3osg04u9fk3jK3-_H7z39SNqmVMistoAQLTss3UT6MTl4ir7WYmHKh4_ODyMc0Qzz5QoPOuyeHmDqS5HMwi4LZTqmsDNXZlUSBV23k6QehDBIAHVKl-zLT8OiJs6joeBPNW890ikknER2cWsGSdeuGAU7VR7PN7ovljKkRy-kBizXouBQuzFJ0O8MhC5nMIWO6E0boHy9WzJZEwRalby8JNGHuHUIT3Y4LUKzO93USIxEpiUVnvDFskruCXbVdTrUVhaUr4w4x414mhJu3XHuH1_5TdmKtnCeKtZUE58EkTVWFVXDvvR-pO4TUdG08T4jNxU99jBTqL6_bNxTTHp24uHc2r9rHuNjlYbk5Pi618zT5zLFPzSVjVClrzVZSnQqIJV1LQkdNdBXeAEX3odGKltPCeXxmGzI1dMaHodJKdcUWgvPES6zWj8GqkvYFalKcJf0OsS6asK-G9yinx062ExxQfGh1U0YP4ybWHDUNYqEhfY_MXIn9Y3p5gzXTg39oZ9f8Zh9XPcrBBMDzF37cZpbkoHHIJUO0foaV2FhaGH_m32311Oi98sbbNpkC5dYWeAMBAoQ5oSt6YmUwlhhKJ7hYGoTqa9AdoIM2FBQm7LcGSOdQ9rBwolpjoWXMs7V0UFW1c8JI5oHJHZ6XNJimGmWug8H9uMcvKCFgT-GtbVaWTKRysyXyTSiJvCUsJ0yeST8qnDt2JsACNcIYWejntGLKveGxEjpXfcOxDRuoEKz5UnBKJVLXUC5kiqfzOBXsxUhrKe5_sWu9If4yosicT2cmLy2BbRZqaRLGXjtK4cwxtUCKyrzn2J4O911UccDIpHMKdaR-SU_q4NKA3Ay-WRx2nlTwyrNsCprbS0LoAwHCcPr6yJmlf6SnALK58Rb4qbAB2y8-wjlqMX29WBcn2UgccmLuNHXKQsqM2QyF1kIUAMaFV8BXaMBxGJ2O_OKgypFO0RKBabg3umRHkUJds6fsFaBRJ9e1gQOexOyxaDqnw_F0oI92481LyfA4eEXCEv__rGZrWIXdg5-1F5ykrPo6llLlPYP_FeL5QXwi9HAzv8OZYKFSA07Igvtl-AAajh4BbyWCjzbm27QqHly1auZFcT75snN7K1EQf07yP8tk3gfQrQK4rWBCDp2cVYDpIoU6kTcM5ki8TezGQlD82w4uTkqY0r7hO0QFZD8mRJTLO_T-_C8o6O4e0r-mZtizU102DdLCa9yO0fnjMUU9sMdqtrFdxkM7cq80Hn5K-o34XkIdQdxe4YVGGxqOEB0U30uRWzJHOZcQuAPtMZTC0Mdb7wFs7bfYNqr1s-bi1I9ASbBVEmYhx2XzjA1hZeWtHaRAxRI-VHXYMO08Z0xByLWbpvhc02w8NVuG0UhcjoIKITwAv63b-apexYIbop9bHGMQQv8QmFH9QCorPMKkPozgAUsPBG3SciZlIMZ5oMuPFGA55SToHNvLazpHTPj8BhAL9UC6iak6MsWkwB-DOINZDfINhMabunoj9UCOk9BFCNKbtYBoIyPjQ2_HAEdw9jJO3Ag8y7IcYeQJ4RjYR2ysaeoRAFvCHrMiZKYn3ATSvHOiJnF3AMrLRHOmRyiCTRaJaAERNOgOeCoJXK9ifAYUfAi788AcgnpF4xh8t5I6OacmYoLLQ3CIgPLXobMbH1doU8OH8zrv9cCeksWWK2JKOv2ar4rYHOfsn6D9gCN9TA4-1PKcemgoJGPlGIT9gEj2BLojqsKcbp8jakzMzDg7OWrCOUor5eoZROcrvAXQQ3Nv4vtyuHYoyIf1SacMiSqMrLVIShCfXnKqy50kNBWMX1ked4TvPQAgY7TyfEaBUrMrQj4lEKRRK-zoQYQV9DH2_fDHjiHS79xrcGp1IUtPqiQIBYof4qqNBNU3aISZ7PDnRMKs86CAqkislgQ-AFQm5PJSYqYsq3ATGnj6rgkOspR47Cl5TmMz5ovKoU2hgfxIj6LQtT2qfN5jgVfydrtJDJ9BPYobwNgMbcmFLdNBNgTwBfkeZiITiK3SZlAJaOx9ksY1Ew5QBiqxzwIk9FHwr5tGbTByYxnZBCHkOj4JLRu70glwKfHcL_MRUBjYRoIsYOgBzzXPsIUt6sd5NHUnvW9I2t1_MNK1VcNKKViNuudIWlGEtFBvJXSTampu7fFVkwdztm1UnnyZuFlSV0O1tzbIEuvUDiUJFi_1DEY90NLu6Xx26qFeUqXj3s4jeVGzX3Q7aBRGsXx26rd45fBO6mFSUqXhZt4zMeGbxo3puw4l33GXIgHBbGBTQ5TObs_Up3gWXCPY2lX_q0HBzbApoosDg3LxnMrcYHJEhQi4oGXjqOYscnO6GIY7VgGHnwAg8FOafIekD_QaloMr0mpS5o6_JloZJX38yRG7LzetBSQG8XCY-qHY8oGAlYX5VImBUom4yZX-N13DwZXsJ33RY66tS0BTRVVr5b8pOW2jzuMNi4LkIx6RL67voCEEqORTeGql7YSMm0GXHxFG1_gaOUTe0u5cT5F0Xb07nyLaNaHXCzgO9ks7728__wE7U5Ti_KAtEArCOl_BLwn2wpYXN2A5yCe6axYt46xBPB1Vce3Iq8awtO4NcH029w9DW8TTI17a04vM5g8uOx0raDqfOalCMmVPiMMC0N35H_I1OPA62BZUXuoyXgeY8oYdxh0YlSJC8GZ8L3R6Y_9OoKRsQrdOYHRycCoEeUa7rheb8y2mopusFtYXhVXb0ZW9DDX6o2b4uYoyn_yvxoz8N25IUB8vvs86k9HwwKjso4kF88mOFpAI8nOSaPEqy2mDcC7J-4aCTaP6e_uVm40]--></g></svg>;" vertex="1" parent="1">
            <mxGeometry x="210" y="160" width="394" height="151" as="geometry" />
          </mxCell>
        </UserObject>
      </root>
    </mxGraphModel>
  </diagram>
</mxfile>
